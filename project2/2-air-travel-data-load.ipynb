{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Create the raw layer for the Air Travel warehouse"
      ],
      "metadata": {
        "id": "anm6v6_ni078"
      },
      "id": "anm6v6_ni078"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data files into BQ tables"
      ],
      "metadata": {
        "id": "2Sg0zDi2ifT6"
      },
      "id": "2Sg0zDi2ifT6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helpful links:\n",
        "*   [BQ Client](https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client)\n",
        "*   [LoadJobConfig](https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.job.LoadJobConfig)\n"
      ],
      "metadata": {
        "id": "Kw9XlFLqh-Ef"
      },
      "id": "Kw9XlFLqh-Ef"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create BQ dataset for storing the raw data"
      ],
      "metadata": {
        "id": "jjCBZFNK-Ajt"
      },
      "id": "jjCBZFNK-Ajt"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = \"cs329e-sp2025\"\n",
        "dataset = \"air_travel_raw\"\n",
        "region = \"us-central1\"\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "dataset_id = bigquery.Dataset(f\"{project_id}.{dataset}\")\n",
        "dataset_id.location = region\n",
        "resp = bq_client.create_dataset(dataset_id, exists_ok=True)\n",
        "print(\"Created dataset {}.{}\".format(bq_client.project, resp.dataset_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgmFndB9auLN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744672969,
          "user_tz": 360,
          "elapsed": 460,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0a0dc195-0078-4c9a-ae3d-d8717c44f294"
      },
      "id": "fgmFndB9auLN",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset cs329e-sp2025.air_travel_raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Common functions"
      ],
      "metadata": {
        "id": "dIpTO2xz-XIE"
      },
      "id": "dIpTO2xz-XIE"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = \"cs329e-sp2025\"\n",
        "bucket = \"air-travel-open-access\"\n",
        "parent_folder = \"initial-load\"\n",
        "region = \"us-central1\"\n",
        "dataset = \"air_travel_raw\"\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "def create_load_table_from_csv(folder, file_name, table, schema, delimiter=\",\", quote_character=\"\\\"\"):\n",
        "\n",
        "  uri = f\"gs://{bucket}/{parent_folder}/{folder}/{file_name}\"\n",
        "  table_id = f\"{project_id}.{dataset}.{table}\"\n",
        "\n",
        "  table = bigquery.Table(table_id, schema=schema)\n",
        "  table = bq_client.create_table(table, exists_ok=True)\n",
        "  print(\"Created table {}\".format(table.table_id))\n",
        "\n",
        "  # remove the data_source and load_time fields before loading the data,\n",
        "  # neither one is present in the csv\n",
        "  del schema[-1]\n",
        "  del schema[-1]\n",
        "  print(schema)\n",
        "\n",
        "  job_config = bigquery.LoadJobConfig(\n",
        "        schema=schema,\n",
        "        skip_leading_rows=1,\n",
        "        source_format=bigquery.SourceFormat.CSV,\n",
        "        write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
        "        field_delimiter=delimiter,\n",
        "        quote_character=quote_character,\n",
        "        allow_jagged_rows=True,\n",
        "        ignore_unknown_values=True\n",
        "      )\n",
        "\n",
        "  load_job = bq_client.load_table_from_uri(uri, table_id, job_config=job_config)\n",
        "  load_job.result()\n",
        "\n",
        "  destination_table = bq_client.get_table(table_id)\n",
        "  print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
        "\n",
        "\n",
        "def create_load_table_from_json(folder, file_name, table, schema):\n",
        "\n",
        "  table_id = f\"{project_id}.{dataset}.{table}\"\n",
        "\n",
        "  table = bigquery.Table(table_id, schema=schema)\n",
        "  table = bq_client.create_table(table, exists_ok=True)\n",
        "  print(\"Created table {}\".format(table.table_id))\n",
        "\n",
        "  # remove the data_source and load_time fields before loading the data,\n",
        "  # neither one is present in the json\n",
        "  del schema[-1]\n",
        "  del schema[-1]\n",
        "\n",
        "  #print(schema)\n",
        "\n",
        "  job_config = bigquery.LoadJobConfig(schema=schema,\n",
        "      source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
        "      write_disposition = \"WRITE_EMPTY\"\n",
        "  )\n",
        "\n",
        "  uri = f\"gs://{bucket}/{parent_folder}/{folder}/{file_name}\"\n",
        "\n",
        "  load_job = bq_client.load_table_from_uri(\n",
        "      uri,\n",
        "      table_id,\n",
        "      location=region,\n",
        "      job_config=job_config,\n",
        "  )\n",
        "\n",
        "  load_job.result()\n",
        "\n",
        "  destination_table = bq_client.get_table(table_id)\n",
        "  print(\"Loaded {} rows.\".format(destination_table.num_rows))\n"
      ],
      "metadata": {
        "id": "EXGnLdb9-agW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744710155,
          "user_tz": 360,
          "elapsed": 287,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "EXGnLdb9-agW",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and load `airport_businesses`"
      ],
      "metadata": {
        "id": "vK_VU2ioYUvb"
      },
      "id": "vK_VU2ioYUvb"
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"airport-maps/out\"\n",
        "file_name = \"*.csv\"\n",
        "table = \"airport_businesses\"\n",
        "delimiter = \"\\t\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"airport_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"terminal\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"business\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"category\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"location\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"menu_items\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'airportguide'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "id": "oWd7itfuYmwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744716751,
          "user_tz": 360,
          "elapsed": 4104,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "bbcc9216-088f-4a03-86bd-4d99137b5c0b"
      },
      "id": "oWd7itfuYmwE",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table airport_businesses\n",
            "[SchemaField('airport_code', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('terminal', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('business', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('category', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('location', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('menu_items', 'STRING', 'NULLABLE', None, None, (), None)]\n",
            "Loaded 1574 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and load `flight_delays`"
      ],
      "metadata": {
        "id": "YShL34IqFVc-"
      },
      "id": "YShL34IqFVc-"
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"on-time-performance\"\n",
        "file_name = \"*.csv\"\n",
        "table = \"flight_delays\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"year\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"month\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"carrier\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"carrier_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"airport\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"airport_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"arr_flights\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"arr_del15\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"carrier_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"weather_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"nas_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"security_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"late_aircraft_ct\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"arr_cancelled\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"arr_diverted\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"arr_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"carrier_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"weather_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"nas_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"security_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"late_aircraft_delay\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'transtats'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vSJRLZgFsgs",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744757951,
          "user_tz": 360,
          "elapsed": 9674,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "322ceead-19a8-4525-d9c6-cc38736e0c52"
      },
      "id": "_vSJRLZgFsgs",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table flight_delays\n",
            "[SchemaField('year', 'INTEGER', 'REQUIRED', None, None, (), None), SchemaField('month', 'INTEGER', 'REQUIRED', None, None, (), None), SchemaField('carrier', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('carrier_name', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('airport', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('airport_name', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('arr_flights', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('arr_del15', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('carrier_ct', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('weather_ct', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('nas_ct', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('security_ct', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('late_aircraft_ct', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('arr_cancelled', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('arr_diverted', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('arr_delay', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('carrier_delay', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('weather_delay', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('nas_delay', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('security_delay', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('late_aircraft_delay', 'FLOAT', 'NULLABLE', None, None, (), None)]\n",
            "Loaded 381186 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and load `airlines`, `airports`, `countries`, `aircrafts`, and `flight_routes`\n",
        "##### Note: This dataset comes with 5 tables"
      ],
      "metadata": {
        "id": "Y0Wiral9N4GO"
      },
      "id": "Y0Wiral9N4GO"
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"airlines.csv\"\n",
        "table = \"airlines\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"airline_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"alias\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"iata\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"icao\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"callsign\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"country\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"active\", \"BOOL\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bmyjKSBOOBm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744767925,
          "user_tz": 360,
          "elapsed": 4294,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2f0cb13f-a8a3-4939-c32c-b8cf02258937"
      },
      "id": "8bmyjKSBOOBm",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table airlines\n",
            "[SchemaField('airline_id', 'INTEGER', 'REQUIRED', None, None, (), None), SchemaField('name', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('alias', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('iata', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('icao', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('callsign', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('country', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('active', 'BOOL', 'REQUIRED', None, None, (), None)]\n",
            "Loaded 6162 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"airports_ext.csv\"\n",
        "table = \"airports\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"airport_id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"airport_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"city\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"country\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"iata\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"icao\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"latitude\", \"BIGNUMERIC\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"longitude\", \"BIGNUMERIC\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"altitude\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"timezone\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"daylight_savings_time\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"tz_database_timezone\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"type\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"source\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yVzBiAcPbr2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744906750,
          "user_tz": 360,
          "elapsed": 3848,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7ea276a5-073e-40ea-ebe1-e33aaa9a78bc"
      },
      "id": "5yVzBiAcPbr2",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table airports\n",
            "[SchemaField('airport_id', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('airport_name', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('city', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('country', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('iata', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('icao', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('latitude', 'BIGNUMERIC', 'REQUIRED', None, None, (), None), SchemaField('longitude', 'BIGNUMERIC', 'REQUIRED', None, None, (), None), SchemaField('altitude', 'INTEGER', 'REQUIRED', None, None, (), None), SchemaField('timezone', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('daylight_savings_time', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('tz_database_timezone', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('type', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('source', 'STRING', 'REQUIRED', None, None, (), None)]\n",
            "Loaded 12668 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"countries.csv\"\n",
        "table = \"countries\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"country_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"iso_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"dafif_code\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uR6KvyqQ1pq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744915072,
          "user_tz": 360,
          "elapsed": 5903,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e183b0da-cc00-4949-8718-fcefd5b251e8"
      },
      "id": "2uR6KvyqQ1pq",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table countries\n",
            "[SchemaField('country_name', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('iso_code', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('dafif_code', 'STRING', 'NULLABLE', None, None, (), None)]\n",
            "Loaded 261 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"planes.csv\"\n",
        "table = \"aircrafts\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"aircraft_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"iata_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"icao_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_Wh1xhsTE9p",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744926508,
          "user_tz": 360,
          "elapsed": 5041,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b295071b-35f6-4c32-9b56-d8af8d8c530e"
      },
      "id": "U_Wh1xhsTE9p",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table aircrafts\n",
            "[SchemaField('aircraft_name', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('iata_code', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('icao_code', 'STRING', 'REQUIRED', None, None, (), None)]\n",
            "Loaded 246 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"openflights\"\n",
        "file_name = \"routes.csv\"\n",
        "table = \"flight_routes\"\n",
        "delimiter = \",\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"airline_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"airline_id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"source_airport\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"source_airport_id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"dest_airport\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"dest_airport_id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"codeshare\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"stops\", \"INTEGER\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"equipment\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'openflights'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6_RirNnUhFR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744931383,
          "user_tz": 360,
          "elapsed": 4877,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "279af9da-85f2-4696-c558-9b8c0c1c152a"
      },
      "id": "A6_RirNnUhFR",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table flight_routes\n",
            "[SchemaField('airline_code', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('airline_id', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('source_airport', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('source_airport_id', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('dest_airport', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('dest_airport_id', 'STRING', 'REQUIRED', None, None, (), None), SchemaField('codeshare', 'BOOLEAN', 'NULLABLE', None, None, (), None), SchemaField('stops', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('equipment', 'STRING', 'NULLABLE', None, None, (), None)]\n",
            "Loaded 67663 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and load `airport_reviews`"
      ],
      "metadata": {
        "id": "l1CjL4vEWUpW"
      },
      "id": "l1CjL4vEWUpW"
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"our-airports\"\n",
        "file_name = \"*.tsv\"\n",
        "table = \"airport_reviews\"\n",
        "delimiter = \"\\t\"\n",
        "quote_character = \"'\"\n",
        "\n",
        "schema = [\n",
        "  bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
        "  bigquery.SchemaField(\"threadRef\", \"INTEGER\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"airportRef\", \"INTEGER\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"airportIdent\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"date\", \"DATETIME\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"memberNickname\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"subject\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"body\", \"STRING\", mode=\"NULLABLE\"),\n",
        "  bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'ourairports'\"),\n",
        "  bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "create_load_table_from_csv(folder, file_name, table, schema, delimiter, quote_character)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q80Hi4IGWVC4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744938638,
          "user_tz": 360,
          "elapsed": 7258,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6c0ba572-db3d-4586-9bc2-48f99411b514"
      },
      "id": "q80Hi4IGWVC4",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table airport_reviews\n",
            "[SchemaField('id', 'INTEGER', 'REQUIRED', None, None, (), None), SchemaField('threadRef', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('airportRef', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('airportIdent', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('date', 'DATETIME', 'NULLABLE', None, None, (), None), SchemaField('memberNickname', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('subject', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('body', 'STRING', 'NULLABLE', None, None, (), None)]\n",
            "Loaded 15451 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and load tsa_reports"
      ],
      "metadata": {
        "id": "dLBwAyOWbypa"
      },
      "id": "dLBwAyOWbypa"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "table = \"tsa_traffic\"\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"date\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"hour\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"airport_code\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"airport_name\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"city\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"state\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"checkpoint\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bigquery.SchemaField(\"total_count\", \"INTEGER\"),\n",
        "    bigquery.SchemaField(\"_data_source\", \"STRING\", mode=\"REQUIRED\", default_value_expression=\"'tsa-foia'\"),\n",
        "    bigquery.SchemaField(\"_load_time\", \"TIMESTAMP\", mode=\"REQUIRED\", default_value_expression=\"CURRENT_TIMESTAMP\"),\n",
        "]\n",
        "\n",
        "# create table\n",
        "table_id = f\"{project_id}.{dataset}.{table}\"\n",
        "table = bigquery.Table(table_id, schema=schema)\n",
        "table = bq_client.create_table(table, exists_ok=True)\n",
        "print(\"Created table {}\".format(table.table_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaoRBX7Ab6C1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737744942487,
          "user_tz": 360,
          "elapsed": 206,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0b1cd21e-9764-488f-9bea-5ccea92a1a2a"
      },
      "id": "AaoRBX7Ab6C1",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table tsa_traffic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function\n",
        "\n",
        "import time\n",
        "\n",
        "def convert_to_dict(filepath):\n",
        "\n",
        "    rows_to_insert = []\n",
        "\n",
        "    for line_num, line in enumerate(list(open(filepath))):\n",
        "        #print(f\"{line_num}: {line}\")\n",
        "\n",
        "        if \"{\" == line.strip():\n",
        "            start_dict = line_num\n",
        "            #print(\"start_dict:\", start_dict)\n",
        "\n",
        "        if \"},\" in line.strip():\n",
        "            end_dict = line_num\n",
        "            #print(\"end_dict:\", end_dict)\n",
        "\n",
        "            dict_list = list(open(filepath))[start_dict+1:end_dict]\n",
        "            record = {}\n",
        "\n",
        "            for entry in dict_list:\n",
        "                entry_str = entry.replace(\"\\n\", \"\").replace(\",\", \"\")\n",
        "                key = entry_str.split(\":\")[0].replace('\"', '').strip()\n",
        "\n",
        "                if key in (\"hour_of_day\", \"Hour of Day\", \"hour of day\"):\n",
        "                    key = \"hour\"\n",
        "\n",
        "                if key in (\"Airport Code\", \"airport code\"):\n",
        "                    key = \"airport_code\"\n",
        "\n",
        "                if key in (\"Airport Name\", \"airport name\"):\n",
        "                    key = \"airport_name\"\n",
        "\n",
        "                if key in (\"Customer Traffic\", \"customer traffic\", \"customer_traffic\"):\n",
        "                    key = \"total_count\"\n",
        "\n",
        "                val = entry_str.split(\":\")[1].replace('\"', '').strip()\n",
        "\n",
        "                if key == \"total_count\":\n",
        "                    if val.isdigit():\n",
        "                        val = int(val)\n",
        "                    else:\n",
        "                        print(\"*** Count must be an int, invalid value: \", val)\n",
        "                        continue\n",
        "\n",
        "                record[key] = val\n",
        "\n",
        "            rows_to_insert.append(record)\n",
        "\n",
        "    return rows_to_insert\n",
        "\n",
        "\n",
        "def write_to_BQ(bq_client, table_id, rows_to_insert):\n",
        "\n",
        "    print(\"write to BQ\")\n",
        "    is_error = False\n",
        "\n",
        "    try:\n",
        "\n",
        "        table = bq_client.get_table(table_id)\n",
        "        schema = table.schema\n",
        "        del schema[-1]\n",
        "        del schema[-1]\n",
        "\n",
        "        job_config = bigquery.LoadJobConfig(schema=schema,\n",
        "                                            source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
        "                                            write_disposition='WRITE_APPEND')\n",
        "\n",
        "        load_job = bq_client.load_table_from_json(rows_to_insert, destination=table_id, job_config=job_config)\n",
        "        load_job.result()\n",
        "\n",
        "        if load_job.errors:\n",
        "            print('Errors while writing to table:', load_job.errors)\n",
        "            is_error = True\n",
        "\n",
        "    except Exception as e:\n",
        "        print('Error while writing to table:', e)\n",
        "        if '404' in str(e):\n",
        "            # table isn't open for writes (it may have been just created)\n",
        "            print('Table not ready to be written to. Sleeping for 5 seconds.')\n",
        "            time.sleep(5)\n",
        "            try:\n",
        "                load_job = bq_client.load_table_from_json(rows_to_insert, destination=table_id, job_config=job_config)\n",
        "                load_job.result()\n",
        "            except Exception as e:\n",
        "                print('Error occurred while writing to table: {}'.format(e))\n",
        "                is_error = True\n",
        "\n",
        "    return is_error"
      ],
      "metadata": {
        "id": "jrkZeCI-eb95",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737745020867,
          "user_tz": 360,
          "elapsed": 124,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "jrkZeCI-eb95",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import storage\n",
        "\n",
        "bucket = \"air-travel-open-access\"\n",
        "folder = \"initial-load/tsa-traffic/llm-text/\"\n",
        "\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# read files from GCS\n",
        "blobs = storage_client.list_blobs(bucket, prefix=folder)\n",
        "for blob in blobs:\n",
        "    file_path = \"/tmp/\" + blob.name.split(\"/\")[3]\n",
        "    print(f\"processing {file_path}\")\n",
        "    blob.download_to_filename(file_path)\n",
        "    rows_to_insert = convert_to_dict(file_path)\n",
        "    is_error = write_to_BQ(bq_client, table_id, rows_to_insert)\n",
        "\n",
        "    if is_error == True:\n",
        "        break\n",
        "    else:\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "id": "XRADPZg-z9HK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737745482220,
          "user_tz": 360,
          "elapsed": 434289,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f1bd50cc-0cb5-415b-b3a2-ccb77d56b600"
      },
      "id": "XRADPZg-z9HK",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing /tmp/april-14-2024-to-april-20-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-14-2024-to-april-20-2024_501_998.txt\n",
            "write to BQ\n",
            "processing /tmp/april-16-2023-to-april-22-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-16-2023-to-april-22-2023_501_987.txt\n",
            "write to BQ\n",
            "processing /tmp/april-21-2024-to-april-27-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-21-2024-to-april-27-2024_501_997.txt\n",
            "write to BQ\n",
            "processing /tmp/april-23-2023-to-april-29-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-23-2023-to-april-29-2023_501_986.txt\n",
            "write to BQ\n",
            "processing /tmp/april-7-2024-to-april-13-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-7-2024-to-april-13-2024_501_986.txt\n",
            "write to BQ\n",
            "processing /tmp/april-9-2023-to-april-15-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/april-9-2023-to-april-15-2023_501_985.txt\n",
            "write to BQ\n",
            "processing /tmp/august-13-2023-to-august-19-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-13-2023-to-august-19-2023_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/august-14-2022-to-august-20-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-14-2022-to-august-20-2022_501_988.txt\n",
            "write to BQ\n",
            "processing /tmp/august-20-2023-to-august-26-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-20-2023-to-august-26-2023_501_982.txt\n",
            "write to BQ\n",
            "processing /tmp/august-21-2022-to-august-27-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-21-2022-to-august-27-2022_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/august-6-2023-to-august-12-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-6-2023-to-august-12-2023_501_982.txt\n",
            "write to BQ\n",
            "processing /tmp/august-7-2022-to-august-13-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/august-7-2022-to-august-13-2022_501_982.txt\n",
            "write to BQ\n",
            "processing /tmp/december-10-2023-to-december-16-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-10-2023-to-december-16-2023_501_983.txt\n",
            "write to BQ\n",
            "processing /tmp/december-11-2022-to-december-17-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-11-2022-to-december-17-2022_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/december-17-2023-to-december-23-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-17-2023-to-december-23-2023_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/december-24-2023-to-december-30-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-24-2023-to-december-30-2023_501_985.txt\n",
            "write to BQ\n",
            "processing /tmp/december-4-2022-to-december-10-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/december-4-2022-to-december-10-2022_501_994.txt\n",
            "write to BQ\n",
            "processing /tmp/february-12-2023-to-february-18-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/february-12-2023-to-february-18-2023_501_991.txt\n",
            "write to BQ\n",
            "processing /tmp/february-18-2024-to-february-24-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/february-18-2024-to-february-24-2024_501_996.txt\n",
            "write to BQ\n",
            "processing /tmp/february-19-2023-to-february-25-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/february-19-2023-to-february-25-2023_501_983.txt\n",
            "write to BQ\n",
            "processing /tmp/february-4-2024-to-february-10-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/february-4-2024-to-february-10-2024_501_991.txt\n",
            "write to BQ\n",
            "processing /tmp/january-14-2024-to-january-20-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/january-14-2024-to-january-20-2024_501_993.txt\n",
            "write to BQ\n",
            "processing /tmp/january-15-2023-to-january-21-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/january-15-2023-to-january-21-2023_501_987.txt\n",
            "write to BQ\n",
            "processing /tmp/january-21-2024-to-january-27-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/january-21-2024-to-january-27-2024_501_992.txt\n",
            "write to BQ\n",
            "processing /tmp/january-22-2023-to-january-28-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/january-22-2023-to-january-28-2023_501_993.txt\n",
            "write to BQ\n",
            "processing /tmp/july-10-2022-to-july-16-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-10-2022-to-july-16-2022_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/july-14-2024-to-july-20-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-14-2024-to-july-20-2024_501_985.txt\n",
            "write to BQ\n",
            "processing /tmp/july-16-2023-to-july-22-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-16-2023-to-july-22-2023_501_983.txt\n",
            "write to BQ\n",
            "processing /tmp/july-21-2024-to-july-27-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-21-2024-to-july-27-2024_501_986.txt\n",
            "write to BQ\n",
            "processing /tmp/july-23-2023-to-july-29-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-23-2023-to-july-29-2023_501_983.txt\n",
            "*** Count must be an int, invalid value:  null\n",
            "write to BQ\n",
            "processing /tmp/july-24-2022-to-july-30-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-24-2022-to-july-30-2022_501_996.txt\n",
            "write to BQ\n",
            "processing /tmp/july-28-2024-to-august-3-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-28-2024-to-august-3-2024_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/july-7-2024-to-july-13-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-7-2024-to-july-13-2024_501_998.txt\n",
            "write to BQ\n",
            "processing /tmp/july-9-2023-to-july-15-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/july-9-2023-to-july-15-2023_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/june-11-2023-to-june-17-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-11-2023-to-june-17-2023_501_993.txt\n",
            "write to BQ\n",
            "processing /tmp/june-12-2022-to-june-18-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-12-2022-to-june-18-2022_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/june-16-2024-to-june-22-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-16-2024-to-june-22-2024_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/june-18-2023-to-june-24-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-18-2023-to-june-24-2023_501_997.txt\n",
            "write to BQ\n",
            "processing /tmp/june-23-2024-to-june-29-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-23-2024-to-june-29-2024_501_997.txt\n",
            "write to BQ\n",
            "processing /tmp/june-4-2023-to-june-10-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-4-2023-to-june-10-2023_501_988.txt\n",
            "write to BQ\n",
            "processing /tmp/june-9-2024-to-june-15-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/june-9-2024-to-june-15-2024_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/march-10-2024-to-march-16-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-10-2024-to-march-16-2024_501_992.txt\n",
            "write to BQ\n",
            "processing /tmp/march-12-2023-to-march-18-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-12-2023-to-march-18-2023_501_992.txt\n",
            "write to BQ\n",
            "processing /tmp/march-17-2024-to-march-23-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-17-2024-to-march-23-2024_501_992.txt\n",
            "write to BQ\n",
            "processing /tmp/march-19-2023-to-march-25-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-19-2023-to-march-25-2023_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/march-24-2024-to-march-30-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/march-24-2024-to-march-30-2024_501_996.txt\n",
            "write to BQ\n",
            "processing /tmp/may-19-2024-to-may-25-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/may-19-2024-to-may-25-2024_501_990.txt\n",
            "write to BQ\n",
            "processing /tmp/may-21-2023-to-may-27-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/may-21-2023-to-may-27-2023_501_987.txt\n",
            "write to BQ\n",
            "processing /tmp/may-5-2024-to-may-11-2024_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/may-5-2024-to-may-11-2024_501_988.txt\n",
            "write to BQ\n",
            "processing /tmp/november-12-2023-to-november-18-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/november-12-2023-to-november-18-2023_501_991.txt\n",
            "write to BQ\n",
            "processing /tmp/november-13-2022-to-november-19-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/november-13-2022-to-november-19-2022_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/november-20-2022-to-november-26-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/november-20-2022-to-november-26-2022_501_991.txt\n",
            "write to BQ\n",
            "processing /tmp/november-5-2023-to-november-11-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/november-5-2023-to-november-11-2023_501_987.txt\n",
            "write to BQ\n",
            "processing /tmp/october-15-2023-to-october-21-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-15-2023-to-october-21-2023_501_981.txt\n",
            "write to BQ\n",
            "processing /tmp/october-16-2022-to-october-22-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-16-2022-to-october-22-2022_501_998.txt\n",
            "write to BQ\n",
            "processing /tmp/october-22-2023-to-october-28-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-22-2023-to-october-28-2023_501_997.txt\n",
            "write to BQ\n",
            "processing /tmp/october-23-2022-to-october-29-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-23-2022-to-october-29-2022_501_999.txt\n",
            "write to BQ\n",
            "processing /tmp/october-8-2023-to-october-14-2023_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/october-8-2023-to-october-14-2023_501_984.txt\n",
            "write to BQ\n",
            "processing /tmp/september-4-2022-to-september-10-2022_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/september-4-2022-to-september-10-2022_501_988.txt\n",
            "write to BQ\n",
            "processing /tmp/tsa_throughput_data_november_19_2017_to_november_25_2017_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/tsa_throughput_data_november_19_2017_to_november_25_2017_501_898.txt\n",
            "write to BQ\n",
            "processing /tmp/tsa_throughput_data_november_26_2017_to_december_02_2017_1_500.txt\n",
            "write to BQ\n",
            "processing /tmp/tsa_throughput_data_november_26_2017_to_december_02_2017_501_912.txt\n",
            "write to BQ\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "2-air-travel-data-load.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}